diff --git a/mmdet3d/__init__.py b/mmdet3d/__init__.py
index 643c39c..001b224 100644
--- a/mmdet3d/__init__.py
+++ b/mmdet3d/__init__.py
@@ -19,7 +19,7 @@ def digit_version(version_str):
 
 
 mmcv_minimum_version = '1.5.2'
-mmcv_maximum_version = '1.7.0'
+mmcv_maximum_version = '1.7.2'
 mmcv_version = digit_version(mmcv.__version__)
 
 
diff --git a/mmdet3d/apis/train.py b/mmdet3d/apis/train.py
index 4d97026..be10ecd 100644
--- a/mmdet3d/apis/train.py
+++ b/mmdet3d/apis/train.py
@@ -4,7 +4,7 @@ import warnings
 
 import numpy as np
 import torch
-from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
+from mmcv.device.npu import NPUDataParallel, NPUDistributedDataParallel
 from mmcv.runner import (HOOKS, DistSamplerSeedHook, EpochBasedRunner,
                          Fp16OptimizerHook, OptimizerHook, build_optimizer,
                          build_runner, get_dist_info)
@@ -103,13 +103,13 @@ def train_segmentor(model,
         find_unused_parameters = cfg.get('find_unused_parameters', False)
         # Sets the `find_unused_parameters` parameter in
         # torch.nn.parallel.DistributedDataParallel
-        model = MMDistributedDataParallel(
+        model = NPUDistributedDataParallel(
             model.cuda(),
             device_ids=[torch.cuda.current_device()],
             broadcast_buffers=False,
             find_unused_parameters=find_unused_parameters)
     else:
-        model = MMDataParallel(
+        model = NPUDataParallel(
             model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)
 
     # build runner
@@ -223,13 +223,13 @@ def train_detector(model,
         find_unused_parameters = cfg.get('find_unused_parameters', False)
         # Sets the `find_unused_parameters` parameter in
         # torch.nn.parallel.DistributedDataParallel
-        model = MMDistributedDataParallel(
+        model = NPUDistributedDataParallel(
             model.cuda(),
             device_ids=[torch.cuda.current_device()],
             broadcast_buffers=False,
             find_unused_parameters=find_unused_parameters)
     else:
-        model = MMDataParallel(
+        model = NPUDataParallel(
             model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)
 
     # build runner
diff --git a/mmdet3d/models/model_utils/spatial_cross_attention.py b/mmdet3d/models/model_utils/spatial_cross_attention.py
index 22dabac..8562d5e 100644
--- a/mmdet3d/models/model_utils/spatial_cross_attention.py
+++ b/mmdet3d/models/model_utils/spatial_cross_attention.py
@@ -23,6 +23,7 @@ from .multi_scale_deformable_attn_function import MultiScaleDeformableAttnFuncti
 
 ext_module = ext_loader.load_ext(
     '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])
+import mx_driving
 
 
 @TRANSFORMER_LAYER_SEQUENCE.register_module()
@@ -661,10 +662,8 @@ class MSDeformableAttention(BaseModule):
                 f' 2 or 4, but get {reference_points.shape[-1]} instead.')
 
         if torch.cuda.is_available() and value.is_cuda:
-
-            output = MultiScaleDeformableAttnFunction_fp32.apply(
-                value, spatial_shapes, level_start_index, sampling_locations,
-                attention_weights, self.im2col_step)
+            output = mx_driving.multi_scale_deformable_attn(value, spatial_shapes, level_start_index,
+                                                        sampling_locations, attention_weights)
         else:
             output = multi_scale_deformable_attn_pytorch(
                 value, spatial_shapes, sampling_locations, attention_weights)
diff --git a/mmdet3d/models/necks/view_transformer.py b/mmdet3d/models/necks/view_transformer.py
index fd692ae..110f3f6 100644
--- a/mmdet3d/models/necks/view_transformer.py
+++ b/mmdet3d/models/necks/view_transformer.py
@@ -8,7 +8,7 @@ from mmdet.models.backbones.resnet import BasicBlock
 from torch.cuda.amp.autocast_mode import autocast
 from torch.utils.checkpoint import checkpoint
 
-from mmdet3d.ops.bev_pool_v2.bev_pool import bev_pool_v2
+from mx_driving import bev_pool_v3
 from ..builder import NECKS
 
 
@@ -147,19 +147,15 @@ class LSSViewTransformer(BaseModule):
                 (B, N_cams, D, H, W, C).
         """
 
-        ranks_bev, ranks_depth, ranks_feat, \
-            interval_starts, interval_lengths = \
+        ranks_bev, ranks_depth, ranks_feat = \
             self.voxel_pooling_prepare_v2(coor)
 
         self.ranks_bev = ranks_bev.int().contiguous()
         self.ranks_feat = ranks_feat.int().contiguous()
         self.ranks_depth = ranks_depth.int().contiguous()
-        self.interval_starts = interval_starts.int().contiguous()
-        self.interval_lengths = interval_lengths.int().contiguous()
 
     def voxel_pooling_v2(self, coor, depth, feat):
-        ranks_bev, ranks_depth, ranks_feat, \
-            interval_starts, interval_lengths = \
+        ranks_bev, ranks_depth, ranks_feat = \
             self.voxel_pooling_prepare_v2(coor)
         if ranks_feat is None:
             print('warning ---> no points within the predefined '
@@ -176,13 +172,20 @@ class LSSViewTransformer(BaseModule):
         bev_feat_shape = (depth.shape[0], int(self.grid_size[2]),
                           int(self.grid_size[1]), int(self.grid_size[0]),
                           feat.shape[-1])  # (B, Z, Y, X, C)
-        bev_feat = bev_pool_v2(depth, feat, ranks_depth, ranks_feat, ranks_bev,
-                               bev_feat_shape, interval_starts,
-                               interval_lengths)
+        bev_feat = bev_pool_v3(depth, feat, ranks_depth, ranks_feat, ranks_bev,
+                               bev_feat_shape)
         # collapse Z
         bev_feat = torch.cat(bev_feat.unbind(dim=2), 1)
         return bev_feat
 
+    def index_func(self, inp, mask):
+        mask_clone = mask.detach()
+        if inp.dim() == 1:
+            return torch.masked_select(inp, mask_clone)
+        else: # inp.dim() == 2
+            mask_clone = mask_clone.unsqueeze(1).expand(inp.shape)
+            return torch.masked_select(inp, mask_clone).view(-1, inp.shape[1])
+
     def voxel_pooling_prepare_v2(self, coor):
         """Data preparation for voxel pooling.
 
@@ -219,29 +222,16 @@ class LSSViewTransformer(BaseModule):
                (coor[:, 2] >= 0) & (coor[:, 2] < self.grid_size[2])
         if len(kept) == 0:
             return None, None, None, None, None
-        coor, ranks_depth, ranks_feat = \
-            coor[kept], ranks_depth[kept], ranks_feat[kept]
+        coor = self.index_func(coor, kept)
+        ranks_depth = self.index_func(ranks_depth, kept)
+        ranks_feat = self.index_func(ranks_feat, kept)
         # get tensors from the same voxel next to each other
         ranks_bev = coor[:, 3] * (
                 self.grid_size[2] * self.grid_size[1] * self.grid_size[0])
         ranks_bev += coor[:, 2] * (self.grid_size[1] * self.grid_size[0])
         ranks_bev += coor[:, 1] * self.grid_size[0] + coor[:, 0]
-        order = ranks_bev.argsort()
-        ranks_bev, ranks_depth, ranks_feat = \
-            ranks_bev[order], ranks_depth[order], ranks_feat[order]
-
-        kept = torch.ones(
-            ranks_bev.shape[0], device=ranks_bev.device, dtype=torch.bool)
-        kept[1:] = ranks_bev[1:] != ranks_bev[:-1]
-        interval_starts = torch.where(kept)[0].int()
-        if len(interval_starts) == 0:
-            return None, None, None, None, None
-        interval_lengths = torch.zeros_like(interval_starts)
-        interval_lengths[:-1] = interval_starts[1:] - interval_starts[:-1]
-        interval_lengths[-1] = ranks_bev.shape[0] - interval_starts[-1]
         return ranks_bev.int().contiguous(), ranks_depth.int().contiguous(
-        ), ranks_feat.int().contiguous(), interval_starts.int().contiguous(
-        ), interval_lengths.int().contiguous()
+        ), ranks_feat.int().contiguous()
 
     def pre_compute(self, input):
         if self.initial_flag:
@@ -260,10 +250,9 @@ class LSSViewTransformer(BaseModule):
             bev_feat_shape = (depth.shape[0], int(self.grid_size[2]),
                               int(self.grid_size[1]), int(self.grid_size[0]),
                               feat.shape[-1])  # (B, Z, Y, X, C)
-            bev_feat = bev_pool_v2(depth, feat, self.ranks_depth,
+            bev_feat = bev_pool_v3(depth, feat, self.ranks_depth,
                                    self.ranks_feat, self.ranks_bev,
-                                   bev_feat_shape, self.interval_starts,
-                                   self.interval_lengths)
+                                   bev_feat_shape)
 
             bev_feat = bev_feat.squeeze(2)
         else:
diff --git a/mmdet3d/models/necks/view_transformer_bevnext.py b/mmdet3d/models/necks/view_transformer_bevnext.py
index 7aa79c6..aa57061 100644
--- a/mmdet3d/models/necks/view_transformer_bevnext.py
+++ b/mmdet3d/models/necks/view_transformer_bevnext.py
@@ -10,6 +10,7 @@ from .depthnet import DepthNet
 from .view_transformer import LSSViewTransformerBEVDepth
 from ..builder import NECKS
 from ...ops.bev_pool_v2.bev_pool import bev_pool_v2
+from ...ops.unfold_with_conv2d.unfold_with_conv2dback import UnfoldConv2dBackward
 
 
 @torch.no_grad()
@@ -54,7 +55,7 @@ class MeanField(nn.Module):
                 nn.Parameter(0.01 * torch.ones(1), requires_grad=False)
             ],
         )
-        self.unfold = torch.nn.Unfold(self.kernel_size, stride=1, padding=self.kernel_size // 2)
+        self.unfold = UnfoldConv2dBackward(self.kernel_size, stride=1, padding=self.kernel_size // 2)
 
     def forward(self, color, feats, logits):
         kernels = [
diff --git a/mmdet3d/ops/bev_pool_v2/bev_pool.py b/mmdet3d/ops/bev_pool_v2/bev_pool.py
index fe16145..1b42443 100644
--- a/mmdet3d/ops/bev_pool_v2/bev_pool.py
+++ b/mmdet3d/ops/bev_pool_v2/bev_pool.py
@@ -3,7 +3,7 @@
 import numpy as np
 import torch
 
-from . import bev_pool_v2_ext
+from mx_driving import bev_pool_v3
 
 __all__ = ['bev_pool_v2', 'TRTBEVPoolv2']
 
@@ -136,9 +136,7 @@ class TRTBEVPoolv2(torch.autograd.Function):
         depth = depth.view(1, n, d, h, w)
         bev_feat_shape = (depth.shape[0], 1, out_height, out_width,
                           feat.shape[-1])  # (B, Z, Y, X, C)
-        bev_feat = bev_pool_v2(depth, feat, ranks_depth, ranks_feat, ranks_bev,
-                               bev_feat_shape, interval_starts,
-                               interval_lengths)
+        bev_feat = bev_pool_v3(depth, feat, ranks_depth, ranks_feat, ranks_bev, bev_feat_shape)
         bev_feat = bev_feat.squeeze(2)
         bev_feat = bev_feat.permute(0, 2, 3, 1)
         return bev_feat
diff --git a/mmdet3d/ops/unfold_with_conv2d/__init__.py b/mmdet3d/ops/unfold_with_conv2d/__init__.py
new file mode 100644
index 0000000..06af069
--- /dev/null
+++ b/mmdet3d/ops/unfold_with_conv2d/__init__.py
@@ -0,0 +1 @@
+# Copyright (c) Phigent Robotics. All rights reserved.
diff --git a/mmdet3d/ops/unfold_with_conv2d/unfold_with_conv2dback.py b/mmdet3d/ops/unfold_with_conv2d/unfold_with_conv2dback.py
new file mode 100644
index 0000000..90e54e9
--- /dev/null
+++ b/mmdet3d/ops/unfold_with_conv2d/unfold_with_conv2dback.py
@@ -0,0 +1,70 @@
+import torch
+import torch.nn as nn
+import torch.nn.functional as F
+import torch_npu
+
+
+class UnfoldWithConv2dBackward(torch.autograd.Function):
+    @staticmethod
+    def forward(ctx, inp, kernel_size, stride, padding):
+        ctx.save_for_backward(inp)
+        ctx.input_shape = inp.shape
+        ctx.kernel_size = kernel_size
+        ctx.stride = stride
+        ctx.padding = padding
+
+        unfold = nn.Unfold(kernel_size=kernel_size, stride=stride, padding=padding)
+        output = unfold(inp)
+        return output
+
+    @staticmethod
+    def backward(ctx, grad_output):
+        (inp,) = ctx.saved_tensors
+        input_shape = ctx.input_shape
+        kernel_size = ctx.kernel_size
+        stride = ctx.stride
+        padding = ctx.padding
+
+        C = input_shape[1]
+
+        weight = torch.zeros(kernel_size**2 * C, C, kernel_size, kernel_size)
+        for i in range(C):
+            for j in range(kernel_size**2):
+                row = j // kernel_size
+                col = j % kernel_size
+                weight[i * kernel_size**2 + j, i, row, col] = 1
+        weight.data = weight.to(grad_output.device)
+
+        N, Ck2, L = grad_output.shape
+        H_out = (input_shape[2] + 2 * padding - kernel_size) // stride + 1
+        W_out = (input_shape[3] + 2 * padding - kernel_size) // stride + 1
+        grad_output_reshaped = grad_output.view(N, Ck2, H_out, W_out)
+
+        conv2d_dx, conv2d_dw, conv2d_db = torch_npu.npu_conv2d_backward(
+            inp,
+            grad_output_reshaped,
+            weight,
+            stride=[stride, stride],
+            padding=[padding, padding],
+            dilation=[1, 1],
+            groups=1,
+            output_mask=[True, False, False]
+        )
+        return conv2d_dx, None, None, None
+
+
+
+class UnfoldConv2dBackward(nn.Module):
+    def __init__(self, kernel_size, stride=1, padding=0):
+        super().__init__()
+        self.kernel_size = kernel_size
+        self.stride = stride
+        self.padding = padding
+
+    def forward(self, x):
+        return UnfoldWithConv2dBackward.apply(
+            x,
+            self.kernel_size,
+            self.stride,
+            self.padding
+        )
\ No newline at end of file
diff --git a/tools/test.py b/tools/test.py
index ad61e21..63275e0 100644
--- a/tools/test.py
+++ b/tools/test.py
@@ -7,9 +7,13 @@ import mmcv
 import torch
 from mmcv import Config, DictAction
 from mmcv.cnn import fuse_conv_bn
-from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
+from mmcv.device.npu import NPUDataParallel, NPUDistributedDataParallel
 from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,
                          wrap_fp16_model)
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
+from mx_driving.patcher.patcher import PatcherBuilder, Patch
+from mx_driving.patcher.tensor import batch_matmul
 
 import mmdet
 from mmdet3d.apis import single_gpu_test
@@ -116,7 +120,7 @@ def parse_args():
         choices=['none', 'pytorch', 'slurm', 'mpi'],
         default='none',
         help='job launcher')
-    parser.add_argument('--local_rank', type=int, default=0)
+    parser.add_argument('--local-rank', type=int, default=0)
     args = parser.parse_args()
     if 'LOCAL_RANK' not in os.environ:
         os.environ['LOCAL_RANK'] = str(args.local_rank)
@@ -233,10 +237,10 @@ def main():
         model.PALETTE = dataset.PALETTE
 
     if not distributed:
-        model = MMDataParallel(model, device_ids=cfg.gpu_ids)
+        model = NPUDataParallel(model, device_ids=cfg.gpu_ids)
         outputs = single_gpu_test(model, data_loader, args.show, args.show_dir)
     else:
-        model = MMDistributedDataParallel(
+        model = NPUDistributedDataParallel(
             model.cuda(),
             device_ids=[torch.cuda.current_device()],
             broadcast_buffers=False)
@@ -264,4 +268,6 @@ def main():
 
 
 if __name__ == '__main__':
-    main()
+    pb = PatcherBuilder().add_module_patch("torch", Patch(batch_matmul))
+    with pb.build():
+        main()
diff --git a/tools/train.py b/tools/train.py
index ed9c2a6..c9343d5 100644
--- a/tools/train.py
+++ b/tools/train.py
@@ -12,6 +12,10 @@ import torch
 import torch.distributed as dist
 from mmcv import Config, DictAction
 from mmcv.runner import get_dist_info, init_dist
+import torch_npu
+from torch_npu.contrib import transfer_to_npu
+from mx_driving.patcher.patcher import PatcherBuilder, Patch
+from mx_driving.patcher.tensor import batch_matmul
 
 from mmdet import __version__ as mmdet_version
 from mmdet3d import __version__ as mmdet3d_version
@@ -29,6 +33,8 @@ try:
 except ImportError:
     from mmdet3d.utils import setup_multi_processes
 
+torch.npu.config.allow_internal_format = False
+
 
 def parse_args():
     parser = argparse.ArgumentParser(description='Train a detector')
@@ -93,7 +99,7 @@ def parse_args():
         choices=['none', 'pytorch', 'slurm', 'mpi'],
         default='none',
         help='job launcher')
-    parser.add_argument('--local_rank', type=int, default=0)
+    parser.add_argument('--local-rank', type=int, default=0)
     parser.add_argument(
         '--autoscale-lr',
         action='store_true',
@@ -260,4 +266,6 @@ def main():
 
 
 if __name__ == '__main__':
-    main()
+    pb = PatcherBuilder().add_module_patch("torch", Patch(batch_matmul))
+    with pb.build():
+        main()
