diff --git a/mmdet3d/__init__.py b/mmdet3d/__init__.py
index 643c39c9..a951e2cc 100644
--- a/mmdet3d/__init__.py
+++ b/mmdet3d/__init__.py
@@ -1,4 +1,5 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+# Copyright 2024 Huawei Technologies Co., Ltd
 import mmcv
 
 import mmdet
@@ -19,7 +20,7 @@ def digit_version(version_str):
 
 
 mmcv_minimum_version = '1.5.2'
-mmcv_maximum_version = '1.7.0'
+mmcv_maximum_version = '1.7.2'
 mmcv_version = digit_version(mmcv.__version__)
 
 
diff --git a/mmdet3d/datasets/nuscenes_dataset.py b/mmdet3d/datasets/nuscenes_dataset.py
index 47d6e15e..d974bab1 100644
--- a/mmdet3d/datasets/nuscenes_dataset.py
+++ b/mmdet3d/datasets/nuscenes_dataset.py
@@ -1,4 +1,5 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+# Copyright 2024 Huawei Technologies Co., Ltd
 import tempfile
 from os import path as osp
 
@@ -316,7 +317,7 @@ class NuScenesDataset(Custom3DDataset):
         print('Start to convert detection format...')
         for sample_id, det in enumerate(mmcv.track_iter_progress(results)):
             annos = []
-            boxes = output_to_nusc_box(det, self.with_velocity)
+            boxes = output_to_nusc_box(det)
             sample_token = self.data_infos[sample_id]['token']
             boxes = lidar_nusc_box_to_global(self.data_infos[sample_id], boxes,
                                              mapped_class_names,
@@ -573,7 +574,7 @@ class NuScenesDataset(Custom3DDataset):
                         file_name, show)
 
 
-def output_to_nusc_box(detection, with_velocity=True):
+def output_to_nusc_box(detection):
     """Convert the output to the box class in the nuScenes.
 
     Args:
@@ -593,24 +594,21 @@ def output_to_nusc_box(detection, with_velocity=True):
     box_gravity_center = box3d.gravity_center.numpy()
     box_dims = box3d.dims.numpy()
     box_yaw = box3d.yaw.numpy()
-
-    # our LiDAR coordinate system -> nuScenes box coordinate system
-    nus_box_dims = box_dims[:, [1, 0, 2]]
+    # TODO: check whether this is necessary
+    # with dir_offset & dir_limit in the head
+    box_yaw = -box_yaw - np.pi / 2
 
     box_list = []
     for i in range(len(box3d)):
         quat = pyquaternion.Quaternion(axis=[0, 0, 1], radians=box_yaw[i])
-        if with_velocity:
-            velocity = (*box3d.tensor[i, 7:9], 0.0)
-        else:
-            velocity = (0, 0, 0)
+        velocity = (*box3d.tensor[i, 7:9], 0.0)
         # velo_val = np.linalg.norm(box3d[i, 7:9])
         # velo_ori = box3d[i, 6]
         # velocity = (
         # velo_val * np.cos(velo_ori), velo_val * np.sin(velo_ori), 0.0)
         box = NuScenesBox(
             box_gravity_center[i],
-            nus_box_dims[i],
+            box_dims[i],
             quat,
             label=labels[i],
             score=scores[i],
diff --git a/mmdet3d/datasets/pipelines/loading.py b/mmdet3d/datasets/pipelines/loading.py
index ffbfb40b..a25ecd81 100644
--- a/mmdet3d/datasets/pipelines/loading.py
+++ b/mmdet3d/datasets/pipelines/loading.py
@@ -1,10 +1,11 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+# Copyright 2024 Huawei Technologies Co., Ltd
 import mmcv
 import numpy as np
 
 from mmdet3d.core.points import BasePoints, get_points_type
+from mmdet.datasets.builder import PIPELINES
 from mmdet.datasets.pipelines import LoadAnnotations, LoadImageFromFile
-from ..builder import PIPELINES
 
 
 @PIPELINES.register_module()
@@ -14,10 +15,9 @@ class LoadMultiViewImageFromFiles(object):
     Expects results['img_filename'] to be a list of filenames.
 
     Args:
-        to_float32 (bool, optional): Whether to convert the img to float32.
+        to_float32 (bool): Whether to convert the img to float32.
             Defaults to False.
-        color_type (str, optional): Color type of the file.
-            Defaults to 'unchanged'.
+        color_type (str): Color type of the file. Defaults to 'unchanged'.
     """
 
     def __init__(self, to_float32=False, color_type='unchanged'):
@@ -31,7 +31,7 @@ class LoadMultiViewImageFromFiles(object):
             results (dict): Result dict containing multi-view image filenames.
 
         Returns:
-            dict: The result dict containing the multi-view image data.
+            dict: The result dict containing the multi-view image data. \
                 Added keys and values are described below.
 
                 - filename (str): Multi-view image filenames.
@@ -49,7 +49,7 @@ class LoadMultiViewImageFromFiles(object):
         if self.to_float32:
             img = img.astype(np.float32)
         results['filename'] = filename
-        # unravel to list, see `DefaultFormatBundle` in formatting.py
+        # unravel to list, see `DefaultFormatBundle` in formating.py
         # which will transpose each image separately and then stack into array
         results['img'] = [img[..., i] for i in range(img.shape[-1])]
         results['img_shape'] = img.shape
@@ -78,7 +78,7 @@ class LoadImageFromFileMono3D(LoadImageFromFile):
     detection, additional camera parameters need to be loaded.
 
     Args:
-        kwargs (dict): Arguments are the same as those in
+        kwargs (dict): Arguments are the same as those in \
             :class:`LoadImageFromFile`.
     """
 
@@ -103,22 +103,17 @@ class LoadPointsFromMultiSweeps(object):
     This is usually used for nuScenes dataset to utilize previous sweeps.
 
     Args:
-        sweeps_num (int, optional): Number of sweeps. Defaults to 10.
-        load_dim (int, optional): Dimension number of the loaded points.
-            Defaults to 5.
-        use_dim (list[int], optional): Which dimension to use.
-            Defaults to [0, 1, 2, 4].
-        time_dim (int, optional): Which dimension to represent the timestamps
-            of each points. Defaults to 4.
-        file_client_args (dict, optional): Config dict of file clients,
-            refer to
+        sweeps_num (int): Number of sweeps. Defaults to 10.
+        load_dim (int): Dimension number of the loaded points. Defaults to 5.
+        use_dim (list[int]): Which dimension to use. Defaults to [0, 1, 2, 4].
+        file_client_args (dict): Config dict of file clients, refer to
             https://github.com/open-mmlab/mmcv/blob/master/mmcv/fileio/file_client.py
             for more details. Defaults to dict(backend='disk').
-        pad_empty_sweeps (bool, optional): Whether to repeat keyframe when
+        pad_empty_sweeps (bool): Whether to repeat keyframe when
             sweeps is empty. Defaults to False.
-        remove_close (bool, optional): Whether to remove close points.
+        remove_close (bool): Whether to remove close points.
             Defaults to False.
-        test_mode (bool, optional): If `test_mode=True`, it will not
+        test_mode (bool): If test_model=True used for testing, it will not
             randomly sample sweeps but select the nearest N frames.
             Defaults to False.
     """
@@ -127,7 +122,6 @@ class LoadPointsFromMultiSweeps(object):
                  sweeps_num=10,
                  load_dim=5,
                  use_dim=[0, 1, 2, 4],
-                 time_dim=4,
                  file_client_args=dict(backend='disk'),
                  pad_empty_sweeps=False,
                  remove_close=False,
@@ -135,16 +129,11 @@ class LoadPointsFromMultiSweeps(object):
         self.load_dim = load_dim
         self.sweeps_num = sweeps_num
         self.use_dim = use_dim
-        self.time_dim = time_dim
-        assert time_dim < load_dim, \
-            f'Expect the timestamp dimension < {load_dim}, got {time_dim}'
         self.file_client_args = file_client_args.copy()
         self.file_client = None
         self.pad_empty_sweeps = pad_empty_sweeps
         self.remove_close = remove_close
         self.test_mode = test_mode
-        assert max(use_dim) < load_dim, \
-            f'Expect all used dimensions < {load_dim}, got {use_dim}'
 
     def _load_points(self, pts_filename):
         """Private function to load point clouds data.
@@ -173,7 +162,7 @@ class LoadPointsFromMultiSweeps(object):
 
         Args:
             points (np.ndarray | :obj:`BasePoints`): Sweep points.
-            radius (float, optional): Radius below which points are removed.
+            radius (float): Radius below which points are removed.
                 Defaults to 1.0.
 
         Returns:
@@ -194,18 +183,18 @@ class LoadPointsFromMultiSweeps(object):
         """Call function to load multi-sweep point clouds from files.
 
         Args:
-            results (dict): Result dict containing multi-sweep point cloud
+            results (dict): Result dict containing multi-sweep point cloud \
                 filenames.
 
         Returns:
-            dict: The result dict containing the multi-sweep points data.
+            dict: The result dict containing the multi-sweep points data. \
                 Added key and value are described below.
 
-                - points (np.ndarray | :obj:`BasePoints`): Multi-sweep point
+                - points (np.ndarray | :obj:`BasePoints`): Multi-sweep point \
                     cloud arrays.
         """
         points = results['points']
-        points.tensor[:, self.time_dim] = 0
+        points.tensor[:, 4] = 0
         sweep_points_list = [points]
         ts = results['timestamp']
         if self.pad_empty_sweeps and len(results['sweeps']) == 0:
@@ -232,7 +221,7 @@ class LoadPointsFromMultiSweeps(object):
                 points_sweep[:, :3] = points_sweep[:, :3] @ sweep[
                     'sensor2lidar_rotation'].T
                 points_sweep[:, :3] += sweep['sensor2lidar_translation']
-                points_sweep[:, self.time_dim] = ts - sweep_ts
+                points_sweep[:, 4] = ts - sweep_ts
                 points_sweep = points.new_point(points_sweep)
                 sweep_points_list.append(points_sweep)
 
@@ -255,8 +244,8 @@ class PointSegClassMapping(object):
 
     Args:
         valid_cat_ids (tuple[int]): A tuple of valid category.
-        max_cat_id (int, optional): The max possible cat_id in input
-            segmentation mask. Defaults to 40.
+        max_cat_id (int): The max possible cat_id in input segmentation mask.
+            Defaults to 40.
     """
 
     def __init__(self, valid_cat_ids, max_cat_id=40):
@@ -280,7 +269,7 @@ class PointSegClassMapping(object):
             results (dict): Result dict containing point semantic masks.
 
         Returns:
-            dict: The result dict containing the mapped category ids.
+            dict: The result dict containing the mapped category ids. \
                 Updated key and value are described below.
 
                 - pts_semantic_mask (np.ndarray): Mapped semantic masks.
@@ -319,7 +308,7 @@ class NormalizePointsColor(object):
             results (dict): Result dict containing point clouds data.
 
         Returns:
-            dict: The result dict containing the normalized points.
+            dict: The result dict containing the normalized points. \
                 Updated key and value are described below.
 
                 - points (:obj:`BasePoints`): Points after color normalization.
@@ -346,7 +335,7 @@ class NormalizePointsColor(object):
 class LoadPointsFromFile(object):
     """Load Points From File.
 
-    Load points from file.
+    Load sunrgbd and scannet points from file.
 
     Args:
         coord_type (str): The type of coordinates of points cloud.
@@ -354,17 +343,14 @@ class LoadPointsFromFile(object):
             - 'LIDAR': Points in LiDAR coordinates.
             - 'DEPTH': Points in depth coordinates, usually for indoor dataset.
             - 'CAMERA': Points in camera coordinates.
-        load_dim (int, optional): The dimension of the loaded points.
+        load_dim (int): The dimension of the loaded points.
             Defaults to 6.
-        use_dim (list[int], optional): Which dimensions of the points to use.
+        use_dim (list[int]): Which dimensions of the points to be used.
             Defaults to [0, 1, 2]. For KITTI dataset, set use_dim=4
             or use_dim=[0, 1, 2, 3] to use the intensity dimension.
-        shift_height (bool, optional): Whether to use shifted height.
-            Defaults to False.
-        use_color (bool, optional): Whether to use color features.
-            Defaults to False.
-        file_client_args (dict, optional): Config dict of file clients,
-            refer to
+        shift_height (bool): Whether to use shifted height. Defaults to False.
+        use_color (bool): Whether to use color features. Defaults to False.
+        file_client_args (dict): Config dict of file clients, refer to
             https://github.com/open-mmlab/mmcv/blob/master/mmcv/fileio/file_client.py
             for more details. Defaults to dict(backend='disk').
     """
@@ -420,7 +406,7 @@ class LoadPointsFromFile(object):
             results (dict): Result dict containing point clouds data.
 
         Returns:
-            dict: The result dict containing the point clouds data.
+            dict: The result dict containing the point clouds data. \
                 Added key and value are described below.
 
                 - points (:obj:`BasePoints`): Point clouds data.
@@ -526,7 +512,7 @@ class LoadAnnotations3D(LoadAnnotations):
                  with_seg=False,
                  with_bbox_depth=False,
                  poly2mask=True,
-                 seg_3d_dtype=np.int64,
+                 seg_3d_dtype='int',
                  file_client_args=dict(backend='disk')):
         super().__init__(
             with_bbox,
@@ -608,11 +594,11 @@ class LoadAnnotations3D(LoadAnnotations):
             self.file_client = mmcv.FileClient(**self.file_client_args)
         try:
             mask_bytes = self.file_client.get(pts_instance_mask_path)
-            pts_instance_mask = np.frombuffer(mask_bytes, dtype=np.int64)
+            pts_instance_mask = np.frombuffer(mask_bytes, dtype=np.int)
         except ConnectionError:
             mmcv.check_file_exist(pts_instance_mask_path)
             pts_instance_mask = np.fromfile(
-                pts_instance_mask_path, dtype=np.int64)
+                pts_instance_mask_path, dtype=np.long)
 
         results['pts_instance_mask'] = pts_instance_mask
         results['pts_mask_fields'].append('pts_instance_mask')
@@ -627,22 +613,52 @@ class LoadAnnotations3D(LoadAnnotations):
         Returns:
             dict: The dict containing the semantic segmentation annotations.
         """
+
         pts_semantic_mask_path = results['ann_info']['pts_semantic_mask_path']
+        learning_map =  results['ann_info']['learning_map']
+        lidar_path = results['pts_filename']
+        points_label = np.fromfile(pts_semantic_mask_path, dtype=np.uint8).reshape([-1, 1])
+        points_label = np.vectorize(learning_map.__getitem__)(points_label)
+
+        points = np.fromfile(lidar_path, dtype=np.float32, count=-1).reshape([-1, 5])[:, :3]
+        pts_semantic_mask = np.concatenate((points, points_label.astype(np.uint8)),axis=1)
+
+        # if self.file_client is None:
+        #     self.file_client = mmcv.FileClient(**self.file_client_args)
+        # try:
+        #     mask_bytes = self.file_client.get(pts_semantic_mask_path)
+        #     # add .copy() to fix read-only bug
+        #     pts_semantic_mask = np.frombuffer(
+        #         mask_bytes, dtype=self.seg_3d_dtype).copy()
+        # except ConnectionError:
+        #     mmcv.check_file_exist(pts_semantic_mask_path)
+        #     pts_semantic_mask = np.fromfile(
+        #         pts_semantic_mask_path, dtype=np.long)
+
+        results['pts_semantic_mask'] = pts_semantic_mask
+        results['pts_seg_fields'].append('pts_semantic_mask')
+        return results
+
+    # Add Mask
+    def _load_semantic_seg(self, results):
+        """Private function to load semantic segmentation annotations.
+
+        Args:
+            results (dict): Result dict from :obj:`dataset`.
+
+        Returns:
+            dict: The dict contains loaded semantic segmentation annotations.
+        """
 
         if self.file_client is None:
             self.file_client = mmcv.FileClient(**self.file_client_args)
-        try:
-            mask_bytes = self.file_client.get(pts_semantic_mask_path)
-            # add .copy() to fix read-only bug
-            pts_semantic_mask = np.frombuffer(
-                mask_bytes, dtype=self.seg_3d_dtype).copy()
-        except ConnectionError:
-            mmcv.check_file_exist(pts_semantic_mask_path)
-            pts_semantic_mask = np.fromfile(
-                pts_semantic_mask_path, dtype=np.int64)
 
-        results['pts_semantic_mask'] = pts_semantic_mask
-        results['pts_seg_fields'].append('pts_semantic_mask')
+        # filename = [str.replace('samples','nuscenes_mask_semantic') for str in results['filename']]
+        filename = [str.replace('samples','nuscenes_box_thresh05') for str in results['filename']]
+        filename = [str.replace('jpg','png') for str in filename]
+        results['gt_semantic_seg'] = [mmcv.imfrombytes(self.file_client.get(file), flag='unchanged').squeeze() for file in filename]
+
+        results['seg_fields'].append('gt_semantic_seg')
         return results
 
     def __call__(self, results):
@@ -673,8 +689,10 @@ class LoadAnnotations3D(LoadAnnotations):
         if self.with_seg_3d:
             results = self._load_semantic_seg_3d(results)
 
+
         return results
 
+
     def __repr__(self):
         """str: Return a string that describes the module."""
         indent_str = '    '
diff --git a/mmdet3d/datasets/pipelines/transforms_3d.py b/mmdet3d/datasets/pipelines/transforms_3d.py
index d2dc0760..4b3cd0e5 100644
--- a/mmdet3d/datasets/pipelines/transforms_3d.py
+++ b/mmdet3d/datasets/pipelines/transforms_3d.py
@@ -1,4 +1,5 @@
 # Copyright (c) OpenMMLab. All rights reserved.
+# Copyright 2024 Huawei Technologies Co., Ltd
 import random
 import warnings
 
@@ -922,7 +923,7 @@ class ObjectRangeFilter(object):
         # using mask to index gt_labels_3d will cause bug when
         # len(gt_labels_3d) == 1, where mask=1 will be interpreted
         # as gt_labels_3d[1] and cause out of index error
-        gt_labels_3d = gt_labels_3d[mask.numpy().astype(np.bool)]
+        gt_labels_3d = gt_labels_3d[mask.numpy().astype(np.bool_)]
 
         # limit rad to [-pi, pi]
         gt_bboxes_3d.limit_yaw(offset=0.5, period=2 * np.pi)
@@ -1850,4 +1851,4 @@ class RandomShiftScale(object):
         repr_str = self.__class__.__name__
         repr_str += f'(shift_scale={self.shift_scale}, '
         repr_str += f'aug_prob={self.aug_prob}) '
-        return repr_str
+        return repr_str
\ No newline at end of file
diff --git a/requirements/runtime.txt b/requirements/runtime.txt
index 643cb0cd..d69b5d74 100644
--- a/requirements/runtime.txt
+++ b/requirements/runtime.txt
@@ -1,10 +1,10 @@
 lyft_dataset_sdk
-networkx>=2.2,<2.3
-numba==0.53.0
+networkx==2.8
+numba==0.58.1
 numpy
 nuscenes-devkit
 plyfile
-scikit-image
+scikit-image==0.21.0
 # by default we also use tensorboard to log results
 tensorboard
 trimesh>=2.35.39,<2.35.40
